# downsampling_timeseries

Welcome!

Welcome!

Trusting data-driven decision-making goes beyond demonstrating compliance with 
legal, regulatory and ethical obligations; decision-makers also need to trust 
how the data is used. Handling, storing and visualising the volume of data being 
generated today requires data practitioners to make assumptions and processing 
choices that remain opaque to decision-makers. Downsampling is an established 
technique to select a representative subset of time series data that preserves 
the original data shape while reducing the number of data points in the time 
series. The research outlined by this paper explores decision-makers' trust in 
data, data practitioners' experience of communicating data insights to 
decision-makers and a new visualisation methodology for explaining the impact of 
downsampling on high-volume time series data. It combines user research insights 
from interviews with 16 UK Civil Servants with analysis of time series features 
for 900 imputed time series to identify and visualise the features that are most 
sensitive to downsampling. This research shows the potential for improving 
decision-makers' trust in data by helping data practitioners to create 
transparency in the data processing pipeline, communicate the impact of 
downsampling, and support conversations about which algorithms or parameters are 
most appropriate for particular decision-maker use cases.

To load this project, open the folder `210431461_CSC869_Dissertation` in the 
`reports` folder open the `Rmarkdown` file with the same name. Update the file
paths for your computer set up before runing the file using CRTL + ALT + R, and 
everything should be set up for you!
